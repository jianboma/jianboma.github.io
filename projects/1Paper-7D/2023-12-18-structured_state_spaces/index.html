<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Read `efficiently modeling long sequences with stuctured state spaces` | Jianbo Ma</title> <meta name="author" content="Jianbo Ma"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/profile_head3.png?827aece6b42572b4a67200cce7342aee"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jianboma.github.io/projects/1Paper-7D/2023-12-18-structured_state_spaces/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "Read `efficiently modeling long sequences with stuctured state spaces`",
      "description": "",
      "published": "December 18, 2023",
      "authors": [
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Jianbo </span>Ma</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Submenus</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/publications/">Publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/blog/">Blog</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Read `efficiently modeling long sequences with stuctured state spaces`</h1> <p></p> </d-title><d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#tl-dr">TL;DR</a></div> <div><a href="#d1">D1</a></div> <ul> <li><a href="#state-space-model">State Space Model</a></li> </ul> <div><a href="#d2">D2</a></div> <ul> <li><a href="#hippo">HiPPO</a></li> <li><a href="#discrete-time-ssm">Discrete-time SSM</a></li> </ul> <div><a href="#d3">D3</a></div> <ul> <li><a href="#convolutional-representation">Convolutional representation</a></li> <li><a href="#s4-algorithms">S4 algorithms</a></li> </ul> </nav> </d-contents> <h1 id="efficiently-modeling-long-sequences-with-structured-state-spaces">Efficiently modeling long sequences with structured state spaces</h1> <p>Paper link: <a href="https://arxiv.org/abs/2111.00396" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2111.00396</a><br> <strong>Homepage</strong>: <a href="https://github.com/state-spaces/s4" rel="external nofollow noopener" target="_blank">https://github.com/state-spaces/s4</a> <br></p> <h2 id="tldr">TL;DR</h2> <p>This is a well-written paper. I believe it can be used as an good example for scientific writing. It is worth analysing the structure when comes to writing a paper. Even though many details are quite hard to understand and need more readings of other related materials, the essence of this paper is well emphasized to grasp.</p> <p>Authors proposed an efficient sequence modeling method called Structured State Spaces Model (S3 model), which inspired from state spaces model. The abstract of the paper capture the essence of the paper and directly quoted here,</p> <blockquote> <p>A promising recent approach proposed modeling sequences by simulating the fundamental state space model (SSM) \(x^{'}(t) = Ax(t) + Bu(t)\), \(y(t) = Cx(t) + Du(t)\), and showed that for appropriate choices of the state matrix \(A\), this system could handle long-range dependencies mathematically and empirically. However, this method has prohibitive computation and memory requirements, rendering it infeasible as a general sequence modeling solution. We propose the Structured State Space (S4) sequence model based on a new parameterization for the SSM, and show that it can be computed much more efficiently than prior approaches while preserving their theoretical strengths. Our technique involves conditioning A with a low-rank correction, allowing it to be diagonalized stably and reducing the SSM to the well-studied computation of a Cauchy kernel.</p> </blockquote> <details> <summary>some logs</summary> I think there are still more motivations and insights of the proposed the SSM that can be digged. How is it linked with the neural network and deep learning should be explored more. At least at this stage (reading this paper and relevant papers), <b>I do not have a good understanding about the SSM and its link to neural networks.</b><br> The connection between continuous-time SSM to discrete-time SSM, trade-off, limitations, properties are assumed to be discussed in previous literatures, such as this one <d-cite key="tustin1947method"></d-cite> cited in paper. But it may not be that critical.<br> <b>Another question is that why the original discrete-time SSM does not have a same computational problem.</b> Why does not original discreate-time SSM propose the efficient algorithm? What are the differences between the discrete-time SSM and its usage in the neural networks? </details> <h2 id="d1">D1</h2> <p>Fund the relavent papers from the same group are <a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/05546b0e38ab9175cd905eebcc6ebb76-Paper.pdf" rel="external nofollow noopener" target="_blank">Combining recurrent, convolutional, and continuous-time models with linear state space layers</a> <d-cite key="gu2021combining"></d-cite> (which proposed the LSSL), and <a href="https://proceedings.neurips.cc/paper/2020/file/102f0bb6efb3a6128a3c750dd16729be-Paper.pdf" rel="external nofollow noopener" target="_blank">Hippo: Recurrent memory with optimal polynomial projections</a> <d-cite key="gu2020hippo"></d-cite> (which proposed the HiPPO). For application, the one <a href="https://proceedings.mlr.press/v162/goel22a/goel22a.pdf" rel="external nofollow noopener" target="_blank">It’s raw! audio generation with state-space models</a><d-cite key="goel2022s"></d-cite> is a very interesting one to read.</p> <h3 id="state-space-model">State Space Model</h3> <p>The State Space Models are used in many places. For example, it has been extensively explored in control theory. More read regarding to SSM is needed in order to understand more.</p> <p>The SSM starts as follow,</p> <p> \begin{equation} \label{eq:ssm} \begin{split} x^{'}(t)=\mathbf{A}x(t)+\mathbf{B}u(t) \\ y(t)=\mathbf{C}x(t)+\mathbf{D}u(t) \end{split} \end{equation} </p> <p>As stated in Section 2.1,</p> <blockquote> <p>SSMs are broadly used in many scientific disciplines and related to latent state models such as Hidden Markov Models (HMM). Our goal is to simply use the SSM as a black-box representation in a deep sequence model, where A, B, C, D are parameters learned by gradient descent.</p> </blockquote> <p><mark>An interesting question to ask is how is the SSM related to HMM. How the parameters are trained with gradient descent.</mark> But this is not quite relavent to this paper.</p> <h2 id="d2">D2</h2> <h3 id="hippo">HiPPO</h3> <p>The HiPPO<d-cite key="gu2020hippo"></d-cite> was proposed as the vanillar SSM performs very poorly when it is directly applied in the neural networks naively. There is more details about the HiPPO and this paper introduced the core aspect of it.</p> <p>Instead of ramdonly generating the initial point of \(\mathbf{A}\) in Eq. \(\eqref{eq:ssm}\), it is specified as described in the paper as follow,</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-hippo-matrix-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-hippo-matrix-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-hippo-matrix-1400.webp"></source> <img src="/assets/img/1Paper-7D/ssm_long_sequence/ssm-hippo-matrix.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>The importance of this matrix is interesting, need more reading of the HiPPO paper to get more. But the performance is interesting stated in this paper as,</p> <blockquote> <p>For example, the LSSL (<mark><d-cite key="gu2021combining"></d-cite> I added</mark>) found that simply modifying an SSM from a random matrix \(\mathbf{A}\) to equation (2) improved its performance on the sequential MNIST benchmark from 60% to 98%.</p> </blockquote> <h3 id="discrete-time-ssm">Discrete-time SSM</h3> <p>This is typical in digital signal processing that converts continuous-time signal to discrete-time signal. Usually there will be a sampling rate \(Fs\) and it’s associated step size \(\Delta\). There shall have many literatures to explore the topic converting continuous-time SSM to discrete-time SSM. This paper gives rough idea and shows the equations after the discretization. <mark>I assume the discussion the connection between continuous-time SSM to discrete-time SSM, trade-off, limitations, properties are discussed in previous literatures, such as this one <d-cite key="tustin1947method"></d-cite> cited in paper.</mark></p> <details> <summary>A question</summary> An apect is that if the HiPPO matrix and its theoretical analysis are operated in continuous-time domain? If not, why does not the author first write the `discrete-time SSM` and then `HiPPO`. More details needed. </details> <p>The Eq. \(\eqref{eq:ssm}\) becomes,</p> <p> \begin{equation} \label{eq:discrete-time-ssm} \begin{split} &amp;x_{k}= \bar{\mathbf{A}} x_{k-1} + \bar{\mathbf{B}}u_{k} \quad \bar{\mathbf{A}}=(\mathbf{I} - \Delta /2 \cdot \mathbf{A})^{-1}(\mathbf{I} + \Delta /2 \cdot \mathbf{A}) \\ &amp;y_{k }= \bar{\mathbf{A}} x_{k} \quad \quad \bar{\mathbf{B}}=(\mathbf{I} - \Delta /2 \cdot \mathbf{A})^{-1} \Delta \mathbf{B} \quad \bar{\mathbf{C}}=\mathbf{C}. \end{split} \end{equation} </p> <p><strong>Note that \(\mathbf{D}u(t)\) is omitted for simplicity.</strong></p> <blockquote> <p>the state equation is now a recurrence in \(x_{k}\), allowing the discrete SSM to be computed like an RNN. Concretely, \(x_{k} \in \mathbb{R}^{N}\) can be viewed as a hidden state with transition matrix \(\mathbf{A}\).</p> </blockquote> <h2 id="d3">D3</h2> <h3 id="convolutional-representation">Convolutional representation</h3> <p>The contribution of the paper lies on how authors proposed to efficiently train/compute the convolutional representation of the SSM. It reasons as follow,</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-conv-rep-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-conv-rep-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-conv-rep-1400.webp"></source> <img src="/assets/img/1Paper-7D/ssm_long_sequence/ssm-conv-rep.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>where \(\bar{\mathbf{K}}\) is refered as <strong>SSM convolution kernel</strong>, but it is non-trivial to calculate.</p> <p>As can be seen in Eq. (4-5) in the paper, the computation reqires repeating multiplication by \(\bar{\mathbf{A}}\), which motivates the authors to select structured, canonical format \(\bar{\mathbf{A}}\). However, naive converting it to diagonal matrix is not practical still. Instead, authors made the obervation that the HiPPO matrix can be decomposed as the <em>sum of a normal and low-rank matri</em> and then applying spectral theorem of linear algebra.<mark>The reasons will need more readings.</mark></p> <p>From a rough reading and thinking, the solution combines converting \(\bar{\mathbf{A}}\) into a perticular form through using unitary \(\mathbf{V}\), diagonal \(\mathbf{\Lambda}\), and low-rank factorization \(\mathbf{P}\), \(\mathbf{Q}\). And using <strong>Cauchy kernel</strong> to compute the repeating computation of matrix \(\bar{\mathbf{A}}\).</p> <details> <summary>Algorithm detail</summary> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-algorithm-reasoning-text-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-algorithm-reasoning-text-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-algorithm-reasoning-text-1400.webp"></source> <img src="/assets/img/1Paper-7D/ssm_long_sequence/ssm-algorithm-reasoning-text.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-algorithm-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-algorithm-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-algorithm-1400.webp"></source> <img src="/assets/img/1Paper-7D/ssm_long_sequence/ssm-algorithm.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </details> <h3 id="s4-algorithms">S4 algorithms</h3> <p>The paper reached 4 theorms that smmarize the importance of the paper.</p> <details> <summary>Theorem</summary> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-theorem-1-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-theorem-1-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-theorem-1-1400.webp"></source> <img src="/assets/img/1Paper-7D/ssm_long_sequence/ssm-theorem-1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-theorem-2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-theorem-2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-theorem-2-1400.webp"></source> <img src="/assets/img/1Paper-7D/ssm_long_sequence/ssm-theorem-2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-theorem-3-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-theorem-3-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/1Paper-7D/ssm_long_sequence/ssm-theorem-3-1400.webp"></source> <img src="/assets/img/1Paper-7D/ssm_long_sequence/ssm-theorem-3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </details> <details> <summary>Question about backpropagate</summary> The algorithm listed in the paper is forwarding. How does the part of backprogagation looks like? Is it feasible? How the computations looks like? From the experiments, the backpropagation is solved without mentioning. Does it automatically solved by auto gradient in toolkit like PyTorch? </details> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/for_sssm_long_sequence.bib"></d-bibliography> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Jianbo Ma. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>